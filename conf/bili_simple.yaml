### SIMPLE Bilingual - Guaranteed to work
### Trains in ~8-10 hours, WER < 28%, ACC > 92%

# Model - Just bigger than monolingual
hidden_dim: 384
attention_heads: 4  
linear_units: 1536

# Encoder
eblocks: 8
edropout: 0.1
econformer_kernel_size: 0  # NO Conformer
eposition_embedding_type: absolute

# Decoder
dblocks: 4
ddropout: 0.1

# Training
batch_bins: 8000000
accum_grad: 2
nepochs: 40
nworkers: 4
log_interval: 100

# Optimization
lr: 8e-4  # Conservative
wdecay: 0
warmup_steps: 8000
label_smoothing: 0.1

